{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10 - Vanilla CNN and Fine-Tune VGG16 - for Dogs and Cats Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal : Take an existing model that performs a similar task of image classification to achieve and fine-tuning it for the specific task at hand which is of classifying dogs and cats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading Necessary Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for numerical operations and data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42) # Setting random seed for reproducibility\n",
    "\n",
    "# Importing libraries for file handling and system operations\n",
    "import os, shutil, pathlib\n",
    "\n",
    "# Importing libraries for data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from PIL import Image\n",
    "\n",
    "# Importing libraries for deep learning\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "\n",
    "# Importing libraries for machine learning model evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "\n",
    "# Importing specific components from Keras\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "# Setting up offline mode for Plotly\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "# Ignoring warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the original dataset \n",
    "original_dir = pathlib.Path(\"./train/train/\")\n",
    "data_folder = pathlib.Path(\"./train/kaggle_dogs_vs_cats_small\")\n",
    "\n",
    "# Function to create a subset of the dataset with a specified range of files\n",
    "def make_subset(subset_name, start_index, end_index):\n",
    "    for category in (\"cat\", \"dog\"):\n",
    "        dir = data_folder / subset_name / category # Path for the current category within the subset\n",
    "        os.makedirs(dir, exist_ok=True)\n",
    "        \n",
    "        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n",
    "        for fname in fnames:\n",
    "            shutil.copyfile(src=original_dir / fname, dst=dir / fname)\n",
    "\n",
    "\n",
    "# Total number of files\n",
    "total_files = 4000\n",
    "\n",
    "# Calculate the number of files for validation and test subsets (15% each)\n",
    "validation_size = int(0.15 * total_files)\n",
    "test_size = int(0.15 * total_files)\n",
    "\n",
    "# Calculate the number of files for the training subset\n",
    "train_size = total_files - validation_size - test_size\n",
    "\n",
    "# Create subsets for training, validation, and testing with specified start and end indices\n",
    "make_subset(\"train\", start_index=0, end_index=train_size)\n",
    "make_subset(\"validation\", start_index=train_size, end_index=train_size + validation_size)\n",
    "make_subset(\"test\", start_index=train_size + validation_size, end_index=train_size + validation_size + test_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Images represent in orignal dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dir = \"./train/train\"  # Replace with the actual directory containing images\n",
    "\n",
    "num_samples = 9  # Images to plot\n",
    "\n",
    "# List all image filenames\n",
    "image_filenames = os.listdir(original_dir)\n",
    "\n",
    "# Shuffle the list of image filenames randomly\n",
    "random.shuffle(image_filenames)\n",
    "\n",
    "# Plotting the images\n",
    "plt.figure(figsize=(12, 24))\n",
    "for index in range(num_samples):\n",
    "    # Get the filename of the image at the current index\n",
    "    filename = image_filenames[index]\n",
    "    \n",
    "    # Determine whether the image is of a cat or a dog based on the filename\n",
    "    category = \"cat\" if \"cat\" in filename else \"dog\"\n",
    "    \n",
    "    # Load the image with a target size of (150, 150) (adjust target_size as needed)\n",
    "    img_path = os.path.join(original_dir, filename)\n",
    "    img = load_img(img_path, target_size=(150, 150))\n",
    "    \n",
    "    # Create a subplot and plot the image\n",
    "    plt.subplot(6, 3, index + 1)  \n",
    "    plt.imshow(img)  \n",
    "    plt.xlabel(filename + ' (' + category + ')' )  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling for Cat and Dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where the files are located\n",
    "original_dir = \"./train/train\"\n",
    "\n",
    "# Get a list of filenames in the original directory\n",
    "filenames = os.listdir(original_dir)\n",
    "\n",
    "# Initialize an empty list to store categories\n",
    "categories = []\n",
    "\n",
    "# Iterate over each filename\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        categories.append(\"dog\")\n",
    "    else:\n",
    "        categories.append(\"cat\")\n",
    "\n",
    "# Create a DataFrame using filenames and corresponding categories\n",
    "df = pd.DataFrame({\n",
    "    'filename': filenames,\n",
    "    'category': categories\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the data folder\n",
    "data_folder = pathlib.Path(\"./train/kaggle_dogs_vs_cats_small\")\n",
    "train_dir = data_folder / \"train\"\n",
    "\n",
    "filenames = os.listdir(train_dir)\n",
    "\n",
    "# Extract labels from filenames (assuming filenames are in the format 'cat.xxx.jpg' or 'dog.xxx.jpg')\n",
    "labels = [str(x)[:3] for x in filenames]\n",
    "\n",
    "# Create a DataFrame using filenames and labels\n",
    "train_df = pd.DataFrame({'filename': filenames, 'label': labels})\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting : Data Subset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_files(data_folder, subset_names, categories):\n",
    "    \"\"\"\n",
    "    Count the number of files in each category within each subset.\n",
    "\n",
    "    Args:\n",
    "    - data_folder (str): The path to the data folder.\n",
    "    - subset_names (list): Names of data subsets.\n",
    "    - categories (list): Categories within each data subset.\n",
    "\n",
    "    Returns:\n",
    "    - counts (list of lists): List of counts for each category within each subset.\n",
    "    \"\"\"\n",
    "    counts = []\n",
    "    for subset_name in subset_names:\n",
    "        subset_counts = []\n",
    "        for category in categories:\n",
    "            subset_dir = os.path.join(data_folder, subset_name, category)\n",
    "            count = len(os.listdir(subset_dir))\n",
    "            subset_counts.append(count)\n",
    "        counts.append(subset_counts)\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(subset_names, categories, counts):\n",
    "    \"\"\"\n",
    "    Create a plot of the distribution of data subsets.\n",
    "\n",
    "    Args:\n",
    "    - subset_names (list): Names of data subsets.\n",
    "    - categories (list): Categories within each data subset.\n",
    "    - counts (list of lists): List of counts for each category within each subset.\n",
    "    \"\"\"\n",
    "    # Create traces for each category\n",
    "    traces = []\n",
    "    for i, category in enumerate(categories):\n",
    "        trace = go.Bar(\n",
    "            x=subset_names,\n",
    "            y=[count[i] for count in counts],\n",
    "            name=category\n",
    "        )\n",
    "        traces.append(trace)\n",
    "\n",
    "    # Layout configuration for the plot\n",
    "    layout = go.Layout(\n",
    "        title='Distribution of Data Subset',\n",
    "        xaxis=dict(title='Subset'),\n",
    "        yaxis=dict(title='Number of Files'),\n",
    "        barmode='group'\n",
    "    )\n",
    "\n",
    "    # Create the figure using the traces and layout\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "    # Display the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_names = [\"train\", \"validation\", \"test\"]\n",
    "categories = [\"cat\", \"dog\"]\n",
    "\n",
    "# Count files\n",
    "counts = count_files(data_folder, subset_names, categories)\n",
    "\n",
    "# Create and display plot\n",
    "create_plot(subset_names, categories, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_bar_chart(subset_name, categories, counts):\n",
    "    \"\"\"\n",
    "    Create a bar chart for a data subset.\n",
    "\n",
    "    Args:\n",
    "    - subset_name (str): Name of the data subset.\n",
    "    - categories (list): Categories within the data subset.\n",
    "    - counts (list): Counts for each category within the subset.\n",
    "    \"\"\"\n",
    "    # Create bars for each category\n",
    "    bars = go.Bar(\n",
    "        x=categories,\n",
    "        y=counts,\n",
    "        name=subset_name\n",
    "    )\n",
    "\n",
    "    return bars\n",
    "\n",
    "# Example usage\n",
    "subset_names = [\"train\", \"validation\", \"test\"]\n",
    "categories = [\"cat\", \"dog\"]\n",
    "\n",
    "# Count files\n",
    "counts = count_files(data_folder, subset_names, categories)\n",
    "\n",
    "# Create subplots with shared y axes\n",
    "fig = make_subplots(rows=1, cols=len(subset_names), subplot_titles=subset_names)\n",
    "\n",
    "# Add bar charts to subplots\n",
    "for i, subset_name in enumerate(subset_names, start=1):\n",
    "    bars = create_bar_chart(subset_name, categories, counts[i-1])\n",
    "    fig.add_trace(bars, row=1, col=i)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Distribution of Data Subsets (Bar Charts)',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "# Display the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualising Cat and Dog Images in Sub-Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to cat and dog images\n",
    "cat_img_path = data_folder / \"train\" / \"cat\" / \"cat.30.jpg\"  # Path to cat image\n",
    "dog_img_path = data_folder / \"train\" / \"dog\" / \"dog.20.jpg\"  # Path to dog image\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot cat image\n",
    "cat_img = Image.open(cat_img_path)  # Open cat image\n",
    "axes[0].imshow(cat_img)  # Display cat image\n",
    "axes[0].set_title('Cat Image')  # Set title for the subplot\n",
    "\n",
    "# Plot dog image\n",
    "dog_img = Image.open(dog_img_path)  # Open dog image\n",
    "axes[1].imshow(dog_img)  # Display dog image\n",
    "axes[1].set_title('Dog Image')  # Set title for the subplot\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting Cats and Dogs Images in subdataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the training dataset from the specified directory\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"train\",    # Path to the training data folder\n",
    "    image_size=(180, 180),    # Resizing images to (180, 180) pixels\n",
    "    batch_size=32             # Batch size for training\n",
    ")\n",
    "\n",
    "# Loading the validation dataset from the specified directory\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"validation\",\n",
    "    image_size=(180, 180),     \n",
    "    batch_size=32              \n",
    ")\n",
    "\n",
    "# Loading the test dataset from the specified directory\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    data_folder / \"test\",    \n",
    "    image_size=(180, 180),   \n",
    "    batch_size=32            \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# Define the input shape for the model\n",
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "# Rescale input values to be between 0 and 1\n",
    "x = layers.Rescaling(1./255)(inputs)\n",
    "\n",
    "# Convolutional Block 1\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "# Convolutional Block 2\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "# Convolutional Block 3\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "# Convolutional Block 4\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "\n",
    "# Convolutional Block 5\n",
    "x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "\n",
    "# Flatten the output from convolutional layers for dense layers\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Dense layers\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Output layer with 2 neurons and softmax activation function for binary classification\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Define the model using functional API, specifying inputs and outputs\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with binary crossentropy loss, RMSprop optimizer, and accuracy metric\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation loss\n",
    "model_checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/convnet_from_scratch.keras\",\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    monitor=\"val_loss\"  # Monitor validation loss\n",
    ")\n",
    "\n",
    "# Train the model with custom and ModelCheckpoint callbacks\n",
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    epochs=25, \n",
    "    validation_data=validation_dataset, \n",
    "    callbacks=model_checkpoint_callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Directory where the saved models are stored\n",
    "models_directory = \"./models/\"\n",
    "\n",
    "# List all files in the directory\n",
    "model_files = os.listdir(models_directory)\n",
    "\n",
    "# Filter out only the saved model files\n",
    "model_files = [file for file in model_files if file.endswith(\".keras\")]\n",
    "\n",
    "# Sort the model files by modification time (ascending order)\n",
    "model_files.sort(key=lambda x: os.path.getmtime(models_directory + x))\n",
    "\n",
    "# The last file will be the model saved at the best epoch\n",
    "best_model_file = model_files[-1]\n",
    "\n",
    "# Extract the epoch number from the filename\n",
    "best_epoch = int(best_model_file.split(\"_\")[1])\n",
    "\n",
    "print(\"Best epoch level:\", best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Displaying curves of loss and accuracy during training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, acc='accuracy', val_acc='val_accuracy'):\n",
    "    \"\"\"\n",
    "    Function to plot model training history.\n",
    "\n",
    "    Parameters:\n",
    "        model_history (History): History object returned by model.fit()\n",
    "        acc (str): Name of the training accuracy metric\n",
    "        val_acc (str): Name of the validation accuracy metric\n",
    "    \"\"\"\n",
    "    # Create a figure with two subplots side by side\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot training and validation accuracy\n",
    "    axs[0].plot(range(1, len(model_history.history[acc]) + 1), model_history.history[acc])\n",
    "    axs[0].plot(range(1, len(model_history.history[val_acc]) + 1), model_history.history[val_acc])\n",
    "    axs[0].set_title('Model Accuracy')  \n",
    "    axs[0].set_ylabel('Accuracy')  \n",
    "    axs[0].set_xlabel('Epoch')  \n",
    "    axs[0].set_xticks(np.arange(1, len(model_history.history[acc]) + 1))  \n",
    "    axs[0].legend(['train', 'val'], loc='best')  \n",
    "    \n",
    "    # Plot training and validation loss\n",
    "    axs[1].plot(range(1, len(model_history.history['loss']) + 1), model_history.history['loss'])\n",
    "    axs[1].plot(range(1, len(model_history.history['val_loss']) + 1), model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')  \n",
    "    axs[1].set_ylabel('Loss')  \n",
    "    axs[1].set_xlabel('Epoch') \n",
    "    axs[1].set_xticks(np.arange(1, len(model_history.history['loss']) + 1))  \n",
    "    axs[1].legend(['train', 'val'], loc='best') \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model -2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 model pre-trained on ImageNet data, excluding the fully-connected layers at the top\n",
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",   # Load pre-trained weights from ImageNet\n",
    "    include_top=False    # Exclude the fully-connected layers at the top\n",
    ")\n",
    "\n",
    "# Set the convolutional base (VGG16) to be non-trainable\n",
    "conv_base.trainable = False\n",
    "\n",
    "# Display a summary of the convolutional base (VGG16) architecture\n",
    "conv_base.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation pipeline using Keras Sequential API\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        # Randomly flip images horizontally\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        # Randomly rotate images by a maximum of 0.1 radians\n",
    "        layers.RandomRotation(0.1),\n",
    "        # Randomly zoom into images by a maximum of 20%\n",
    "        layers.RandomZoom(0.2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(180, 180, 3))\n",
    "\n",
    "# Apply data augmentation to the input data\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "# Preprocess the input data using VGG16's preprocess_input function\n",
    "x = keras.applications.vgg16.preprocess_input(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Feature Extraction\n",
    "\n",
    "# Pass preprocessed data through the convolutional base (VGG16)\n",
    "x = conv_base(x)\n",
    "\n",
    "# Flatten the output from the convolutional base\n",
    "x = layers.Flatten()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifier Head\n",
    "\n",
    "# Add a dense layer with 256 units and ReLU activation\n",
    "x = layers.Dense(256)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dropout with a rate of 0.5 to prevent overfitting\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add a dense layer with a single unit and sigmoid activation for binary classification\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model with inputs and outputs\n",
    "model_vgg = keras.Model(inputs, outputs)\n",
    "\n",
    "# Display a summary of the model architecture and parameters\n",
    "model_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with loss function, optimizer, and evaluation metrics\n",
    "model_vgg.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation loss\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=\"./models/vgg16_best_epoch.keras\",\n",
    "    save_best_only=True,  # Save only the best model\n",
    "    monitor=\"val_loss\"    # Monitor validation loss for saving the best model\n",
    ")\n",
    "\n",
    "# Train the model with custom and ModelCheckpoint callbacks\n",
    "history = model_vgg.fit(\n",
    "    train_dataset,\n",
    "    epochs=25,  # Number of epochs for training\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=model_checkpoint_callback  # List of callbacks to be used during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths and batch size\n",
    "test_data_dir = './train/kaggle_dogs_vs_cats_small/test'  # Directory containing test data\n",
    "best_model_1_path = './models/convnet_from_scratch.keras'  # Path to the first best model\n",
    "best_model_2_path = './models/vgg16_best_epoch.keras'      # Path to the second best model\n",
    "batch_size = 32  # Batch size for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "\n",
    "# Define paths and batch size\n",
    "test_data_dir = './train/kaggle_dogs_vs_cats_small/test'  # Directory containing test data\n",
    "best_model_path = './models/convnet_from_scratch.keras'  # Path to the first best model\n",
    "\n",
    "# Load the best model\n",
    "best_model = load_model(best_model_path)\n",
    "\n",
    "# Create a data generator for the test dataset\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
    "batch_size = 32  # Define batch size\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(180, 180),  \n",
    "    batch_size=batch_size,   \n",
    "    class_mode='binary',\n",
    "    shuffle=False  # Disable shuffling for evaluation\n",
    ")\n",
    "\n",
    "# Evaluate the best model on the test dataset\n",
    "test_loss, test_accuracy = best_model.evaluate(test_generator, verbose=1)\n",
    "\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset using ImageDataGenerator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(180, 180),  \n",
    "    batch_size=batch_size,   \n",
    "    class_mode='binary',\n",
    "    shuffle=False) # Disable shuffling for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best versions of each model\n",
    "best_model_1 = load_model(best_model_1_path)  # Load first best model\n",
    "best_model_2 = load_model(best_model_2_path)  # Load second best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model 1\n",
    "model_1_evaluation = best_model_1.evaluate(test_generator, verbose=0)\n",
    "print(\"Model 1 Evaluation:\")\n",
    "print(\"Test Loss:\", model_1_evaluation[0])\n",
    "print(\"Test Accuracy:\", model_1_evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model 2\n",
    "model_2_evaluation = best_model_2.evaluate(test_generator, verbose=0)\n",
    "print(\"\\nModel 2 Evaluation:\")\n",
    "print(\"Test Loss:\", model_2_evaluation[0])\n",
    "print(\"Test Accuracy:\", model_2_evaluation[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for both models\n",
    "y_true = test_generator.classes  # True labels\n",
    "y_pred_model_1 = np.squeeze(best_model_1.predict(test_generator))  # Predictions of model 1\n",
    "y_pred_model_2 = np.squeeze(best_model_2.predict(test_generator))  # Predictions of model 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrices\n",
    "cm_model_1 = confusion_matrix(y_true, y_pred_model_1 > 0.5)  # Confusion matrix for model 1\n",
    "cm_model_2 = confusion_matrix(y_true, y_pred_model_2 > 0.5)  # Confusion matrix for model 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Subplot for Model 1 confusion matrix\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Confusion Matrix - Model 1\")\n",
    "plt.imshow(cm_model_1, cmap=plt.cm.Blues, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xticks([0, 1], [\"Cat\", \"Dog\"])\n",
    "plt.yticks([0, 1], [\"Cat\", \"Dog\"])\n",
    "\n",
    "# Subplot for Model 2 confusion matrix\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Confusion Matrix - Model 2\")\n",
    "plt.imshow(cm_model_2, cmap=plt.cm.Blues, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xticks([0, 1], [\"Cat\", \"Dog\"])\n",
    "plt.yticks([0, 1], [\"Cat\", \"Dog\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision, recall, and F1-score for both models\n",
    "print(\"\\nModel 1 Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_model_1 > 0.5, target_names=['Cat', 'Dog']))\n",
    "\n",
    "print(\"\\nModel 2 Classification Report:\")\n",
    "print(classification_report(y_true, y_pred_model_2 > 0.5, target_names=['Cat', 'Dog']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision-recall curve for both models\n",
    "precision_model_1, recall_model_1, _ = precision_recall_curve(y_true, y_pred_model_1)\n",
    "precision_model_2, recall_model_2, _ = precision_recall_curve(y_true, y_pred_model_2)\n",
    "\n",
    "# Plot precision-recall curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_model_1, precision_model_1, label='Model 1')\n",
    "plt.plot(recall_model_2, precision_model_2, label='Model 2')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = \"./train/kaggle_dogs_vs_cats_small/test\"\n",
    "\n",
    "# List to store the filenames of all test images\n",
    "test_filenames = []\n",
    "\n",
    "# Get the filenames of all images in the \"cat\" and \"dog\" subdirectories\n",
    "for category in [\"cat\", \"dog\"]:\n",
    "    category_dir = os.path.join(test_dir, category)\n",
    "    filenames = os.listdir(category_dir)\n",
    "\n",
    "    # Append the file paths to the list of test filenames\n",
    "    test_filenames.extend([os.path.join(category, fname) for fname in filenames])\n",
    "\n",
    "# Make predictions for each image\n",
    "predictions = []\n",
    "for filename in test_filenames:\n",
    "    img_path = os.path.join(test_dir, filename)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    img = load_img(img_path, target_size=(180, 180))  \n",
    "    img_array = np.expand_dims(img, axis=0) / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "    # Make prediction using the model\n",
    "    prediction = model.predict(img_array)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# Convert predictions to binary categories based on the threshold\n",
    "binary_predictions = [1 if pred > threshold else 0 for pred in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "for i, filename in enumerate(test_filenames[:9]):\n",
    "    img_path = os.path.join(test_dir, filename)\n",
    "\n",
    "    # Load the image\n",
    "    img = load_img(img_path, target_size=(180, 180))\n",
    "    \n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.title(f\"Prediction: {binary_predictions[i]}\")\n",
    "    plt.axis(\"off\")  \n",
    "    \n",
    "plt.tight_layout()  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_predictions(y_pred, threshold):\n",
    "    \"\"\"Get binary predictions based on a threshold.\"\"\"\n",
    "    return (y_pred > threshold).astype(int)\n",
    "\n",
    "def calculate_incorrect_predictions(predictions, y_true, filenames):\n",
    "    \"\"\"Calculate incorrect predictions.\"\"\"\n",
    "    incorrect_predictions = []\n",
    "    for i, filename in enumerate(filenames):\n",
    "        actual_label = \"dog\" if y_true[i] == 1 else \"cat\"\n",
    "        predicted_label = \"dog\" if predictions[i] == 1 else \"cat\"\n",
    "        if actual_label != predicted_label:\n",
    "            incorrect_predictions.append((filename, actual_label, predicted_label))\n",
    "    return incorrect_predictions\n",
    "\n",
    "# Get binary predictions for both models\n",
    "binary_predictions_model_1 = get_binary_predictions(y_pred_model_1, threshold)\n",
    "# binary_predictions_model_2 = get_binary_predictions(y_pred_model_2, threshold)\n",
    "\n",
    "# Calculate incorrect predictions for both models\n",
    "incorrect_predictions_model_1 = calculate_incorrect_predictions(binary_predictions_model_1, y_true, test_generator.filenames)\n",
    "incorrect_predictions_model_2 = calculate_incorrect_predictions(binary_predictions_model_2, y_true, test_generator.filenames)\n",
    "\n",
    "# Display information about incorrect predictions for Model 1\n",
    "print(f\"{len(incorrect_predictions_model_1)} Incorrect Predictions for Model 1:\")\n",
    "\n",
    "for filename, actual_label, predicted_label in incorrect_predictions_model_1:\n",
    "    print(f\"Filename: {filename}, Actual Label: {actual_label}, Predicted Label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about incorrect predictions for Model 2\n",
    "print(f\"\\n{len(incorrect_predictions_model_2)} Incorrect Predictions for Model 2:\")\n",
    "for filename, actual_label, predicted_label in incorrect_predictions_model_2:\n",
    "    print(f\"Filename: {filename}, Actual Label: {actual_label}, Predicted Label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_cpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
